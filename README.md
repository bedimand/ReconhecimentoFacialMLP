# Sistema de Reconhecimento Facial com MLP

Este projeto implementa um sistema completo de reconhecimento facial baseado em uma Rede Neural Perceptron Multicamadas (MLP), contemplando etapas de coleta, prÃ©-processamento, treinamento, avaliaÃ§Ã£o e inferÃªncia em tempo real.

---

## ğŸ“‚ Estrutura do Projeto

- **main.py**            : Ponto de entrada. Exibe menu interativo para executar cada etapa do fluxo.
- **config.yaml**        : Arquivo de configuraÃ§Ã£o com parÃ¢metros (caminhos, tamanho de imagem, hiperparÃ¢metros, controles).
- **src/**               : CÃ³digo-fonte principal organizado por funcionalidade:
  - **model/**              : Arquivos relacionados ao modelo neural:
    - **model.py**          : DefiniÃ§Ã£o da classe `FaceRecognitionMLP`, funÃ§Ãµes de salvar e carregar modelo.
    - **train.py**          : FunÃ§Ã£o `train_model` para treinamento com balanceamento de classes e manifest.
    - **evaluation.py**     : FunÃ§Ãµes de avaliaÃ§Ã£o (acurÃ¡cia, relatÃ³rio de classificaÃ§Ã£o e matriz de confusÃ£o).
  - **face/**               : Processamento de faces:
    - **face_detection.py** : DetecÃ§Ã£o via InsightFace e extraÃ§Ã£o de crops centralizados no nariz.
    - **face_recognition.py** : `TransformFactory` para transformaÃ§Ãµes e rotina de inferÃªncia (`recognize_face`).
    - **preprocessing.py**  : MÃ³dulo de remoÃ§Ã£o de fundo (MediaPipe) e normalizaÃ§Ã£o.
  - **data/**               : ManipulaÃ§Ã£o de dados:
    - **datasets.py**       : DefiniÃ§Ãµes de conjuntos de dados e obtenÃ§Ã£o de classes.
    - **preprocessing_dataset.py** : Rotina em lote para prÃ©-processar dataset completo.
  - **utils/**              : UtilitÃ¡rios diversos:
    - **utils.py**          : UtilitÃ¡rios gerais (console, contagem de imagens, criaÃ§Ã£o de pastas).
    - **visualization.py**  : Desenho de bounding boxes, landmarks, estatÃ­sticas e previews.
    - **config.py**         : Carrega `config.yaml` e fornece mÃ©todos de acesso Ã s configuraÃ§Ãµes.
    - **capture_faces.py**  : Script para extrair faces de uma pasta de imagens (modo batch).
  - **frame_processor.py**  : Integra detecÃ§Ã£o e reconhecimento em um frame de vÃ­deo.

---

## ğŸ“ Requisitos

- Python 3.7 ou superior
- Pacotes (via `pip install -r requirements.txt`):
  - opencv-python
  - torch, torchvision
  - insightface, onnxruntime
  - mediapipe
  - pyyaml
  - numpy, Pillow
  - scikit-learn, matplotlib, tqdm

- (Opcional) GPU compatÃ­vel com CUDA para aceleraÃ§Ã£o

---

## âš™ï¸ ConfiguraÃ§Ã£o

1. Renomeie e adapte `config.yaml` conforme seu ambiente:
   - `paths.dataset_dir`   : DiretÃ³rio para armazenar imagens coletadas
   - `paths.model_save_path`: Caminho para salvar o peso do modelo (`.pth`)
   - `image_processing.target_size`: Tamanho (LÃ—A) do crop de face
   - HiperparÃ¢metros de treinamento (`training.*`)
   - Controles de teclado e cores de visualizaÃ§Ã£o

2. (Opcional) Baixe os modelos do InsightFace em `models/insightface` ou ajuste o `root` no cÃ³digo.

---

## ğŸš€ Fluxo de Uso

Execute:

```bash
python main.py
```

O menu oferece as opÃ§Ãµes:

1. **Detectar e coletar faces (webcam)**
   - Faz detecÃ§Ã£o em tempo real, desenha landmarks e captura crops centralizados no nariz.
   - Aperte tecla configurada para salvar faces individuais ou ative auto-save.

2. **Capturar faces de pasta de imagens**
   - Processa todas as imagens de uma pasta, com ou sem visualizaÃ§Ã£o, salvando crops no dataset.

3. **Treinar modelo de reconhecimento**
   - PrÃ©-requisito: execute prÃ©-processamento ou tenha `_preprocessed` no dataset.
   - Gera um manifest para separar treino e validaÃ§Ã£o, treina o MLP e salva pesos e classes.

4. **Avaliar modelo de reconhecimento**
   - Carrega o modelo salvo, exclui imagens de treino via manifest e calcula acurÃ¡cia e matriz de confusÃ£o.

5. **Reconhecimento em tempo real**
   - Captura vÃ­deo da webcam, detecta faces, aplica remoÃ§Ã£o de fundo, reconhece usando o MLP e exibe rÃ³tulos.

6. **PrÃ©-processar e exportar imagem Ãºnica**
   - Permite carregar e prÃ©-processar um arquivo de imagem, salvando o resultado normalizado.

7. **PrÃ©-processar todas as imagens**
   - Executa em lote o pipeline de remoÃ§Ã£o de fundo + resize em todo o dataset.

8. **Sair**

---

## ğŸ” Detalhes TÃ©cnicos

### DetecÃ§Ã£o e ExtraÃ§Ã£o
- InsightFace (`FaceAnalysis`) detecta bounding boxes, 106 landmarks e 5 pontos-chave (kps).
- `extract_face` centraliza o crop no nariz, dimensiona baseado na distÃ¢ncia interpupilar e redimensiona ao tamanho configurado.

### PrÃ©-processamento
- Offline: `PreprocessModule` usa MediaPipe para remover o fundo antes de salvar imagens em `_preprocessed`.
- Em tempo real: aplica `remove_background_grabcut` antes de normalizar e enviar ao modelo.
- NormalizaÃ§Ã£o: pipeline `ToTensor` + `Normalize` (mÃ©dias e desvios padrÃ£o de ImageNet ou configurados).

### Arquitetura do Modelo
- MLP com camadas fully-connected:  inputâ†’2048â†’1024â†’512â†’128â†’num_classes.
- Dropout opcional, Adam optimizer, CrossEntropyLoss, scheduler e early stopping configurÃ¡veis.
- Balanceamento de classes via amostragem de instÃ¢ncias e manifest.

#### ğŸ§  Entendendo o MLP de forma simples

Uma rede MLP (Perceptron Multicamadas) funciona de maneira semelhante ao cÃ©rebro humano, onde "neurÃ´nios artificiais" processam informaÃ§Ãµes em camadas.

**Como funciona nosso reconhecimento facial:**

1. **TransformaÃ§Ã£o da imagem em nÃºmeros**:
   - Cada imagem de rosto (128Ã—128 pixels) Ã© convertida em uma longa lista de 49.152 nÃºmeros (128Ã—128Ã—3 canais RGB)
   - Ã‰ como "achatar" uma foto colorida em uma Ãºnica fileira de nÃºmeros

2. **Processamento em camadas**:
   - **Primeira camada (2048 neurÃ´nios)**: Recebe os 49.152 nÃºmeros e identifica padrÃµes bÃ¡sicos (como bordas, contornos)
   - **Camadas intermediÃ¡rias (1024â†’512â†’128 neurÃ´nios)**: Combinam esses padrÃµes em caracterÃ­sticas mais complexas (formato dos olhos, nariz, etc.)
   - **Camada final (nÃºmero de pessoas)**: Cada neurÃ´nio representa uma pessoa. O que "acender mais forte" indica quem Ã© reconhecido

3. **DecisÃ£o por "votaÃ§Ã£o"**:
   - ApÃ³s passar pelos cÃ¡lculos internos, cada neurÃ´nio de saÃ­da tem um "valor de ativaÃ§Ã£o"
   - O neurÃ´nio com maior valor determina a pessoa reconhecida
   - Esse valor Ã© convertido em percentual de confianÃ§a (ex: "JoÃ£o: 92.5%")

**Analogia:** Imagine uma sÃ©rie de filtros cada vez mais especÃ­ficos. O primeiro filtro separa "Ã© um rosto?" da imagem inicial. Os filtros seguintes procuram caracterÃ­sticas especÃ­ficas: "tem olhos verdes?", "tem nariz fino?", "tem queixo marcado?". A combinaÃ§Ã£o Ãºnica dessas caracterÃ­sticas permite identificar a pessoa especÃ­fica.

**Durante o treinamento**, o sistema aprende automaticamente quais caracterÃ­sticas sÃ£o mais importantes para distinguir cada pessoa no dataset, ajustando milhÃµes de "pesos" internos que determinam como os padrÃµes sÃ£o interpretados.

**Na identificaÃ§Ã£o em tempo real**, uma nova imagem percorre o mesmo caminho, e a rede compara seus padrÃµes com o que aprendeu anteriormente.

#### Detalhes da Rede MLP

A parte central do sistema Ã© a Rede Neural Multicamadas (MLP) definida em `src/model/model.py` na classe `FaceRecognitionMLP`. Seus principais aspectos sÃ£o:

1. **Tamanho da entrada**
   - Cada crop Ã© redimensionado ao tamanho `(H, W)` configurado em `config.yaml` (`image_processing.target_size`).
   - O tensor resultante tem forma `(C, H, W)` e Ã© achatado para `(C*H*W)` antes de entrar no MLP.

2. **Camadas fully-connected**
   - `fc1`: `input_size` â†’ 2048 unidades
   - `fc2`: 2048 â†’ 1024 unidades
   - `fc3`: 1024 â†’ 512 unidades
   - `fc4`: 512 â†’ 128 unidades
   - `fc5`: 128 â†’ `num_classes` (nÃºmero de pessoas + `unknown`)

3. **FunÃ§Ã£o de ativaÃ§Ã£o**
   - ReLU apÃ³s cada uma das quatro primeiras camadas (`fc1` a `fc4`).
   - Sem ativaÃ§Ã£o na camada de saÃ­da (`fc5`), pois usa logits para `softmax`.

4. **Dropout**
   - Adicionado entre as camadas, se `training.dropout_rate > 0`.
   - Taxa configurÃ¡vel via `config.yaml` (`training.dropout_rate`).

5. **Treinamento**
   - **Perda**: `CrossEntropyLoss` padrÃ£o.
   - **Otimizador**: Adam, com taxa de aprendizado em `training.learning_rate` (padrÃ£o: 0.001).
   - **Early stopping**: Configuraado em `training.early_stopping.patience` (padrÃ£o: 7 Ã©pocas).
   - **Balanceamento**: Amostragem limitada por classe (max `training.sample_per_class` imagens por pessoa).

6. **PersistÃªncia**
   - Ao final do treinamento, `save_model` grava os pesos em `.pth` e a lista de classes em `.pkl`, criando diretÃ³rios automaticamente.

7. **Uso em InferÃªncia**
   - Em `src/face/face_recognition.py`, o mÃ©todo `recognize_face` aplica `softmax` sobre os logits para obter probabilidades.
   - Retorna a classe com maior probabilidade e a confianÃ§a em porcentagem.

Este design simples e direto permite fÃ¡cil treinamento com os dados coletados, mantendo boa performance de reconhecimento.

### AvaliaÃ§Ã£o

#### Resultados

![Matriz de ConfusÃ£o](confusion_matrix.png)

- **Overall accuracy**: 99.33%
- **Detalhes do relatÃ³rio de classificaÃ§Ã£o**:

```
              precision    recall  f1-score   support

  anabeatriz       0.97      0.93      0.95       112
    anapaula       0.94      1.00      0.97       130
    bernardo       0.87      0.96      0.91       376
       livia       0.89      0.97      0.93       147
     unknown       1.00      0.99      1.00     14573

    accuracy                           0.99     15338
   macro avg       0.93      0.97      0.95     15338
weighted avg       0.99      0.99      0.99     15338
```

- **AcurÃ¡cia por classe**:
  - anabeatriz: 92.86%
  - anapaula: 100.00%
  - bernardo: 96.28%
  - livia: 96.60%
  - unknown: 99.48%

#### ConfiguraÃ§Ãµes Utilizadas

As configuraÃ§Ãµes foram carregadas de `config.yaml`:

```yaml
system:
  python_version: "3.11+"
  device: "cuda"

face_detection:
  model_name: "buffalo_s"
  det_size: [640, 640]
  margin: 20

image_processing:
  target_size: [128, 128]
  normalization:
    mean: [0.5]
    std: [0.5]

training:
  num_epochs: 50
  batch_size: 32
  learning_rate: 0.001
  seed: 42
  validation_split: 0.1
  early_stopping:
    enabled: true
    patience: 7

recognition:
  confidence_threshold: 30.0
  looking_detection:
    enabled: true
    threshold: 0.75

camera:
  width: 1280
  height: 720
  fps: 30
```

### Fluxo de Processamento em Tempo Real

O diagrama abaixo mostra as funÃ§Ãµes e configuraÃ§Ãµes aplicadas em cada etapa do reconhecimento em tempo real:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [1] CAPTURA                                                               â”‚
â”‚ - cv2.VideoCapture(0)                                                     â”‚
â”‚ - cap.set(CAP_PROP_FRAME_WIDTH/HEIGHT, config.get('camera.width/height')) â”‚
â”‚ - ret, frame = cap.read()                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [2] DETECÃ‡ÃƒO                                                              â”‚
â”‚ - detect_faces(frame, face_analyzer)                                      â”‚
â”‚ - InsightFaceFaceAnalysis.get(frame)                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [3] LOOP POR FACE                                                         â”‚
â”‚ for face in faces:                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [4] EXTRAÃ‡ÃƒO                                                              â”‚
â”‚ - extract_face(frame, face)                                               â”‚
â”‚ - center_crop_around_nose(...) usando face.bbox e face.kps                â”‚
â”‚ - redimensiona para config.get('image_processing.target_size')            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [5] PRÃ‰-PROCESSAMENTO                                                     â”‚
â”‚ - PreprocessModule.remove_background_grabcut(face_img)                    â”‚
â”‚   (MediaPipe SelfieSegmentation)                                          â”‚
â”‚ - TransformFactory.preprocess_face_tensor(face_no_bg, device)             â”‚
â”‚   (ToTensor, Normalize(mean,std) do config)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [6] INFERÃŠNCIA                                                            â”‚
â”‚ - recognize_face(model, face_img, classes, device)                        â”‚
â”‚ - model(face_tensor) + softmax(outputs)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [7] PÃ“S-PROCESSAMENTO                                                     â”‚
â”‚ - if confidence < config.get('recognition.confidence_threshold'):        â”‚
â”‚     result['label']='Desconhecido'                                        â”‚
â”‚   else: result['label']=nome + f": {confidence:.1f}%"                   â”‚
â”‚ - escolhe result['color'] conforme config                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [8] DESENHO                                                               â”‚
â”‚ - draw_recognition_results(frame, face, result)                           â”‚
â”‚ - draw_stats(frame, fps, process_time, len(faces), extra_info)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [9] EXIBIÃ‡ÃƒO                                                              â”‚
â”‚ - cv2.imshow("Face Recognition", frame)                                 â”‚
â”‚ - key = cv2.waitKey(1) para controle de teclas                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Detalhes de cada etapa:**

1. **Captura**: Frame RGB capturado via OpenCV da webcam (configurÃ¡vel para 1280Ã—720)
2. **DetecÃ§Ã£o**: InsightFace detecta faces, retornando bounding boxes e landmarks (106 + 5 pontos-chave)
3. **Loop de faces**: Cada face detectada Ã© processada separadamente
4. **ExtraÃ§Ã£o**: Recorte da face centralizado no nariz usando distÃ¢ncia interpupilar para escala
5. **PrÃ©-processamento**:
   - RemoÃ§Ã£o de fundo via MediaPipe SelfieSegmentation
   - ConversÃ£o para tensor PyTorch
   - NormalizaÃ§Ã£o usando mÃ©dias/desvios do ImageNet
   - AdiÃ§Ã£o da dimensÃ£o de lote (batch)
6. **InferÃªncia**: Forward pass no MLP seguido de softmax para obter probabilidades
7. **PÃ³s-processamento**:
   - VerificaÃ§Ã£o contra threshold de confianÃ§a (`recognition.confidence_threshold`)
   - DecisÃ£o entre "unknown" e pessoa reconhecida
   - FormataÃ§Ã£o da etiqueta com nome e porcentagem
8. **VisualizaÃ§Ã£o**: Desenho de caixa delimitadora, rÃ³tulo e informaÃ§Ãµes de estatÃ­sticas no frame
9. **ExibiÃ§Ã£o**: ApresentaÃ§Ã£o do frame processado com anotaÃ§Ãµes ao usuÃ¡rio

Este fluxo executa em tempo real em um loop contÃ­nuo, processando cada frame capturado.
